{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "AW_ICP4",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajwkc/CSEE5590/blob/master/AW_ICP4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcF7mmHxbcKq",
        "colab_type": "text"
      },
      "source": [
        "# Classifying Fashion-MNIST\n",
        "\n",
        "Now it's your turn to build and train a neural network. You'll be using the [Fashion-MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), a drop-in replacement for the MNIST dataset. MNIST is actually quite trivial with neural networks where you can easily achieve better than 97% accuracy. Fashion-MNIST is a set of 28x28 greyscale images of clothes. It's more complex than MNIST, so it's a better representation of the actual performance of your network, and a better representation of datasets you'll use in the real world.\n",
        "\n",
        "<img src='assets/fashion-mnist-sprite.png' width=500px>\n",
        "\n",
        "In this notebook, you'll build your own neural network. For the most part, you could just copy and paste the code from Part 3, but you wouldn't be learning. It's important for you to write the code yourself and get it to work. Feel free to consult the previous notebooks though as you work through this.\n",
        "\n",
        "First off, let's load the dataset through torchvision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjXB_3q3bcKs",
        "colab_type": "code",
        "outputId": "f8a00c10-38d5-4856-8a74-77ebea8ddc44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import helper\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:01, 14461275.00it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 99492.51it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:01, 4362729.99it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 38540.45it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FukJWCQ1bcKu",
        "colab_type": "text"
      },
      "source": [
        "Here we can see one of the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft3pgtwybcKv",
        "colab_type": "code",
        "outputId": "f0b5fe16-6fe6-42a3-c830-5d1ac9ee345b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "image, label = next(iter(trainloader))\n",
        "imshow(image[0,:]);"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOsAAADrCAYAAACICmHVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrICJ3wDYEVZLXStiOQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSRRxZgAbcKx",
        "colab_type": "text"
      },
      "source": [
        "## Building the network\n",
        "\n",
        "Here you should define your network. As with MNIST, each image is 28x28 which is a total of 784 pixels, and there are 10 classes. You should include at least one hidden layer. We suggest you use ReLU activations for the layers and to return the logits or log-softmax from the forward pass. It's up to you how many layers you add and the size of those layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aJN7Rx_bcKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Define your network architecture here\n",
        "\n",
        "fashionModel = nn.Sequential(nn.Linear(784, 392),\n",
        "                             nn.ReLU(),\n",
        "                             nn.Linear(392, 196),\n",
        "                             nn.ReLU(),\n",
        "                             nn.Linear(196, 98),\n",
        "                             nn.ReLU(),\n",
        "                             nn.Linear(98,10),\n",
        "                             nn.LogSoftmax(dim=1))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHprNG1GbcKz",
        "colab_type": "text"
      },
      "source": [
        "# Train the network\n",
        "\n",
        "Now you should create your network and train it. First you'll want to define [the criterion](http://pytorch.org/docs/master/nn.html#loss-functions) ( something like `nn.CrossEntropyLoss`) and [the optimizer](http://pytorch.org/docs/master/optim.html) (typically `optim.SGD` or `optim.Adam`).\n",
        "\n",
        "Then write the training code. Remember the training pass is a fairly straightforward process:\n",
        "\n",
        "* Make a forward pass through the network to get the logits \n",
        "* Use the logits to calculate the loss\n",
        "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
        "* Take a step with the optimizer to update the weights\n",
        "\n",
        "By adjusting the hyperparameters (hidden units, learning rate, etc), you should be able to get the training loss below 0.4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks9uCzJwbcKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "dd3f168a-3e00-4636-82fa-4c2336df6e0d"
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(fashionModel.parameters(), lr=0.05)\n",
        "epochs = 4\n",
        "\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images, labels in trainloader:\n",
        "    images = images.reshape(images.shape[0], -1)\n",
        "    optimizer.zero_grad()\n",
        "    output = fashionModel(images)\n",
        "    loss = criterion(output, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss = running_loss + loss.item()\n",
        "  else:\n",
        "    print(f\"Epoch {e+1} Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Training loss: 0.7195489542888426\n",
            "Epoch 2 Training loss: 0.4344951485964789\n",
            "Epoch 3 Training loss: 0.38380573165696313\n",
            "Epoch 4 Training loss: 0.3504032738475022\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giyNMmXlbcK1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d759f9b9-5b7a-4ce7-afc5-64ef6f288260"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = fashionModel(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "view_classify(img.view(1, 28, 28), ps, version=\"Fashion\")\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def test_network(net, trainloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # Create Variables for the inputs and targets\n",
        "    inputs = Variable(images)\n",
        "    targets = Variable(images)\n",
        "\n",
        "    # Clear the gradients from all Variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass, then backward pass, then update weights\n",
        "    output = net.forward(inputs)\n",
        "    loss = criterion(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADPCAYAAACgNEWWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddTsf0F4NQeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def view_recon(img, recon):\n",
        "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
        "        reconstruction also a PyTorch Tensor\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "    axes[0].imshow(img.numpy().squeeze())\n",
        "    axes[1].imshow(recon.data.numpy().squeeze())\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')\n",
        "\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}